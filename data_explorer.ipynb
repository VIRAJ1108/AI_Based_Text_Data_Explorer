{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed89e3c",
   "metadata": {},
   "source": [
    "Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39ecf4bd-ca79-4e45-9ab2-2b525e853ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d58bdc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\viraj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\viraj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "text_data = pd.read_csv(\"data/twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f99b5136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20884</th>\n",
       "      <td>20885</td>\n",
       "      <td>0</td>\n",
       "      <td>radulovicke ððð realmirna  #singer #h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>11089</td>\n",
       "      <td>0</td>\n",
       "      <td>i feel the pain #usopen grounds crew #motherna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>4072</td>\n",
       "      <td>0</td>\n",
       "      <td>yes, i am saying that #hillaryclinton's major ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>4371</td>\n",
       "      <td>0</td>\n",
       "      <td>come on baby!! we want to meet you!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9451</th>\n",
       "      <td>9452</td>\n",
       "      <td>0</td>\n",
       "      <td>@user my money is on @user staying with @user...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "20884  20885      0  radulovicke ððð realmirna  #singer #h...\n",
       "11088  11089      0  i feel the pain #usopen grounds crew #motherna...\n",
       "4071    4072      0  yes, i am saying that #hillaryclinton's major ...\n",
       "4370    4371      0            come on baby!! we want to meet you!!!  \n",
       "9451    9452      0   @user my money is on @user staying with @user..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4613936c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'tweet'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c1e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Lowercase, remove stopwords, lemmatize\n",
    "    \"\"\"\n",
    "    doc = nlp(str(text).lower()) //lowercasing\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and token.text not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
